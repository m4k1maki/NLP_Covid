# Limited Effectiveness of LLM-based Data Augmentation for COVID-19 Misinformation Stance Detection

The repository contains scripts and data used in the paper [Limited Effectiveness of LLM-based Data Augmentation for COVID-19 Misinformation Stance Detection](https://doi.org/10.1145/3701716.3715521).

As for Twitter/X data, we used a dataset collected, documented, and managed by [Chen et al., 2020](https://github.com/echen102/COVID-19-TweetIDs), [Hossain et al., 2020](https://github.com/ucinlp/covid19-data), and [Hou et al., 2022](https://github.com/yanfangh/covid-rumor-stance). To comply with Twitter/X’s [Terms of Service](https://developer.twitter.com/en/developer-terms/agreement-and-policy), we are only publicly releasing the Tweet IDs of the collected Tweets. The data is released for non-commercial research use. 

Before executing the scripts, retrieve the tweet text using the 'tweet_id' field from dataset.json and add a new 'tweet' field for each row in the same JSON file. Use the [API documentation](https://docs.x.com/x-api/posts/post-lookup-by-post-id) to fetch tweets by their IDs.

Script Descriptions:

- `data_check.py`: Identifies trivial and overlapping claim-tweet pairs as detailed in Section 2 DATASETS.
- `pretrain.py`: Pretrains a classifier using the [SNLI](https://huggingface.co/datasets/stanfordnlp/snli), [MNLI](https://huggingface.co/datasets/nyu-mll/multi_nli), and [NLI-FEVER](https://huggingface.co/datasets/pietrolesci/nli_fever) datasets. The pretrained model is saved under `./pretrained_ce`.
- `pretrain_test.py`: Evaluates the pretrained classifier on the test set. Performance is reported under "No DA: Pretrained" in Table 2.
- `augment_trad.py`: Applies [AEDA](https://github.com/akkarimi/aeda_nlp), [EDA](https://github.com/jasonwei20/eda_nlp), and backtranslation to augment the 'tweet' field.
- `augment_cmg.py` [-m]: Conducts CMG augmentation on the 'claim' field using three examples from the 'tweet' field. In practice, the [OpenAI Batch API](https://platform.openai.com/docs/guides/batch) was used to reduce costs when running CMG on OpenAI models (GPT-4o, GPT-3.5-turbo).
- `rejection_score.py`: Computes the rejection score presented in Figure 3.
- `train.py`: Finetunes models with or without augmented data and saves all trained models under `./models`.
- `test.py`: Evaluates the finetuned models, with results shown in Table 2.

This dataset is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International Public License ([CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/)). By using this dataset, you agree to abide by the stipulations in the license, remain in compliance with Twitter’s [Terms of Service](https://developer.twitter.com/en/developer-terms/agreement-and-policy), Meta's [Llama 2 Community License Agreement](https://ai.meta.com/llama/license/), Tongyi Qianwen's [License Agreement](https://github.com/QwenLM/Qwen/blob/main/Tongyi%20Qianwen%20LICENSE%20AGREEMENT), and OpenAI's [Terms of Use](https://openai.com/policies/terms-of-use), and cite the following manuscript: 

Eun Cheol Choi, Ashwin Balasubramanian, Jinhu Qi, Emilio Ferrara. 2025. Limited effectiveness of LLM-based data augmentation for COVID-19 misinformation stance detection. In Companion Proceedings of the ACM Web Conference 2025 (WWW ’25 Companion), Apr 28–May 2, 2025, Sydney, Australia. ACM, New York, NY, USA, 4 pages. https://doi.org/10.1145/3701716.3715521

BibTeX:
```bibtex
@inproceedings{choi2025limited,
  title={Limited effectiveness of LLM-based data augmentation for COVID-19 misinformation stance detection},
  author={Choi, Eun Cheol and Balasubramanian, Ashwin and Qi, Jinhu and Ferrara, Emilio},
  booktitle={Companion Proceedings of the ACM on Web Conference 2025},
  year={2025}
}
```
